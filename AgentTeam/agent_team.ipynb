{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e603178",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec99319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Installation complete.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Installation complete.\n"
     ]
    }
   ],
   "source": [
    "# @title Step 0: Setup and Installation\n",
    "# Install ADK and LiteLLM for multi-model support\n",
    "\n",
    "%pip install google-adk -q\n",
    "%pip install litellm -q\n",
    "\n",
    "print(\"Installation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb68ba",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34c807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# @title Import necessary libraries\n",
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf2a90",
   "metadata": {},
   "source": [
    "## Configure API Key\n",
    "\n",
    "Set up your Google API key for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys Set:\n",
      "Google API Key: âœ— Not set\n",
      "OpenAI API Key: âœ— Not set (optional)\n",
      "Anthropic API Key: âœ— Not set (optional)\n"
     ]
    }
   ],
   "source": [
    "# @title Configure API Keys\n",
    "\n",
    "# --- Load from .env file ---\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load from one of your existing .env files\n",
    "load_dotenv(\"../my_agent/.env\")  # or use \"../multi_tool_agent/.env\"\n",
    "\n",
    "# Read the keys\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Set the environment variables for this notebook session\n",
    "if google_api_key:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
    "else:\n",
    "    print(\"âš ï¸ WARNING: GOOGLE_API_KEY not found in .env file!\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY_HERE\"  # Fallback\n",
    "\n",
    "if openai_api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = anthropic_api_key\n",
    "\n",
    "# --- Verify Keys ---\n",
    "print(\"API Keys Set:\")\n",
    "print(f\"Google API Key: {'âœ“ Found' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_API_KEY_HERE' else 'âœ— Not set'}\")\n",
    "print(f\"OpenAI API Key: {'âœ“ Found' if os.environ.get('OPENAI_API_KEY') else 'âœ— Not set (optional)'}\")\n",
    "print(f\"Anthropic API Key: {'âœ“ Found' if os.environ.get('ANTHROPIC_API_KEY') else 'âœ— Not set (optional)'}\")\n",
    "\n",
    "# Configure ADK to use API keys directly (not Vertex AI)\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n",
    "\n",
    "print(\"\\nðŸ“Œ Note: Loading API key from ../my_agent/.env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c894f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment configured.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "\n",
    "# More supported models can be referenced here: https://ai.google.dev/gemini-api/docs/models#model-variations\n",
    "MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\"\n",
    "\n",
    "# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/openai#openai-chat-completion-models\n",
    "MODEL_GPT_4O = \"openai/gpt-4.1\" # You can also try: gpt-4.1-mini, gpt-4o etc.\n",
    "\n",
    "# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/anthropic\n",
    "MODEL_CLAUDE_SONNET = \"anthropic/claude-sonnet-4-20250514\" # You can also try: claude-opus-4-20250514 , claude-3-7-sonnet-20250219 etc\n",
    "\n",
    "print(\"\\nEnvironment configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da4ce8",
   "metadata": {},
   "source": [
    "## Step 1: Your First Agent - Basic Weather Lookup\n",
    "\n",
    "Let's begin by building the fundamental component of our Weather Bot: a single agent capable of performing a specific task â€“ looking up weather information. This involves creating two core pieces:\n",
    "\n",
    "A Tool: A Python function that equips the agent with the ability to fetch weather data.\n",
    "An Agent: The AI \"brain\" that understands the user's request, knows it has a weather tool, and decides when and how to use it.\n",
    "\n",
    "1. Define the Tool (get_weather)\n",
    "\n",
    "In ADK, Tools are the building blocks that give agents concrete capabilities beyond just text generation. They are typically regular Python functions that perform specific actions, like calling an API, querying a database, or performing calculations.\n",
    "\n",
    "Our first tool will provide a mock weather report. This allows us to focus on the agent structure without needing external API keys yet. Later, you could easily swap this mock function with one that calls a real weather service.\n",
    "\n",
    "Key Concept: Docstrings are Crucial! The agent's LLM relies heavily on the function's docstring to understand:\n",
    "\n",
    "What the tool does.\n",
    "When to use it.\n",
    "What arguments it requires (city: str).\n",
    "What information it returns.\n",
    "Best Practice: Write clear, descriptive, and accurate docstrings for your tools. This is essential for the LLM to use the tool correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3555f8",
   "metadata": {},
   "source": [
    "Define the get_weather Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0cc5db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25Â°C.'}\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
     ]
    }
   ],
   "source": [
    "# @title Define the get_weather Tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the weather information.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'report' key with weather details.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\") # Log tool execution\n",
    "    city_normalized = city.lower().replace(\" \", \"\") # Basic normalization\n",
    "\n",
    "    # Mock weather data\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25Â°C.\"},\n",
    "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15Â°C.\"},\n",
    "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18Â°C.\"},\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n",
    "\n",
    "# Example tool usage (optional test)\n",
    "print(get_weather(\"New York\"))\n",
    "print(get_weather(\"Paris\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8311208e",
   "metadata": {},
   "source": [
    "2. Define the Agent (weather_agent)\n",
    "\n",
    "Now, let's create the Agent itself. An Agent in ADK orchestrates the interaction between the user, the LLM, and the available tools.\n",
    "\n",
    "We configure it with several key parameters:\n",
    "\n",
    "* name: A unique identifier for this agent (e.g., \"weather_agent_v1\").\n",
    "* model: Specifies which LLM to use (e.g., MODEL_GEMINI_2_0_FLASH). We'll start with a specific Gemini model.\n",
    "* description: A concise summary of the agent's overall purpose. This becomes crucial later when other agents need to decide whether to delegate tasks to this agent.\n",
    "* instruction: Detailed guidance for the LLM on how to behave, its persona, its goals, and specifically how and when to utilize its assigned tools.\n",
    "* tools: A list containing the actual Python tool functions the agent is allowed to use (e.g., [get_weather]).\n",
    "__Best Practice__: Provide clear and specific instruction prompts. The more detailed the instructions, the better the LLM can understand its role and how to use its tools effectively. Be explicit about error handling if needed.\n",
    "\n",
    "__Best Practice__: Choose descriptive name and description values. These are used internally by ADK and are vital for features like automatic delegation (covered later)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc9de1",
   "metadata": {},
   "source": [
    "Define the Weather Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9cd9daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'weather_agent_v1' created using model 'gemini-2.0-flash'.\n"
     ]
    }
   ],
   "source": [
    "# @title Define the Weather Agent\n",
    "# Use one of the model constants defined earlier\n",
    "AGENT_MODEL = MODEL_GEMINI_2_0_FLASH # Starting with Gemini\n",
    "\n",
    "weather_agent = Agent(\n",
    "    name=\"weather_agent_v1\",\n",
    "    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n",
    "    description=\"Provides weather information for specific cities.\",\n",
    "    instruction=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information. \"\n",
    "                \"If the tool returns an error, inform the user politely. \"\n",
    "                \"If the tool is successful, present the weather report clearly.\",\n",
    "    tools=[get_weather], # Pass the function directly\n",
    ")\n",
    "\n",
    "print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6fd09f",
   "metadata": {},
   "source": [
    "3. Setup Runner and Session Service\n",
    "\n",
    "To manage conversations and execute the agent, we need two more components:\n",
    "\n",
    "* SessionService: Responsible for managing conversation history and state for different users and sessions. The InMemorySessionService is a simple implementation that stores everything in memory, suitable for testing and simple applications. It keeps track of the messages exchanged. We'll explore state persistence more in Step 4.\n",
    "* Runner: The engine that orchestrates the interaction flow. It takes user input, routes it to the appropriate agent, manages calls to the LLM and tools based on the agent's logic, handles session updates via the SessionService, and yields events representing the progress of the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c347e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created: App='weather_tutorial_app', User='user_1', Session='session_001'\n",
      "Runner created for agent 'weather_agent_v1'.\n"
     ]
    }
   ],
   "source": [
    "# @title Setup Session Service and Runner\n",
    "\n",
    "# --- Session Management ---\n",
    "# Key Concept: SessionService stores conversation history & state.\n",
    "# InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Define constants for identifying the interaction context\n",
    "APP_NAME = \"weather_tutorial_app\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will happen\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "# --- Runner ---\n",
    "# Key Concept: Runner orchestrates the agent execution loop.\n",
    "runner = Runner(\n",
    "    agent=weather_agent, # The agent we want to run\n",
    "    app_name=APP_NAME,   # Associates runs with our app\n",
    "    session_service=session_service # Uses our session manager\n",
    ")\n",
    "print(f\"Runner created for agent '{runner.agent.name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4c3d7",
   "metadata": {},
   "source": [
    "4. Interact with the Agent\n",
    "\n",
    "We need a way to send messages to our agent and receive its responses. Since LLM calls and tool executions can take time, ADK's Runner operates asynchronously.\n",
    "\n",
    "We'll define an async helper function (call_agent_async) that:\n",
    "\n",
    "1. Takes a user query string.\n",
    "2. Packages it into the ADK Content format.\n",
    "3. Calls runner.run_async, providing the user/session context and the new message.\n",
    "4. Iterates through the Events yielded by the runner. Events represent steps in the agent's execution (e.g., tool call requested, tool result received, intermediate LLM thought, final response).\n",
    "5. Identifies and prints the final response event using event.is_final_response().\n",
    "\n",
    "\n",
    "__Why async?__ Interactions with LLMs and potentially tools (like external APIs) are I/O-bound operations. Using asyncio allows the program to handle these operations efficiently without blocking execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a7b3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define Agent Interaction Function\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "async def call_agent_async(query: str, runner, user_id, session_id):\n",
    "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
    "  print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "  # Prepare the user's message in ADK format\n",
    "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
    "\n",
    "  # Key Concept: run_async executes the agent logic and yields Events.\n",
    "  # We iterate through events to find the final answer.\n",
    "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "      # You can uncomment the line below to see *all* events during execution\n",
    "      # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "      if event.is_final_response():\n",
    "          if event.content and event.content.parts:\n",
    "             # Assuming text response in the first part\n",
    "             final_response_text = event.content.parts[0].text\n",
    "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "          # Add more checks here if needed (e.g., specific error codes)\n",
    "          break # Stop processing events once the final response is found\n",
    "\n",
    "  print(f\"<<< Agent Response: {final_response_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d25d1e",
   "metadata": {},
   "source": [
    "5. Run the Conversation\n",
    "\n",
    "Finally, let's test our setup by sending a few queries to the agent. We wrap our async calls in a main async function and run it using await.\n",
    "\n",
    "Watch the output:\n",
    "\n",
    "* See the user queries.\n",
    "* Notice the --- Tool: get_weather called... --- logs when the agent uses the tool.\n",
    "* Observe the agent's final responses, including how it handles the case where weather data isn't available (for Paris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56af9cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What is the weather like in London?\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_async(\u001b[33m\"\u001b[39m\u001b[33mTell me the weather in New York\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m                                        runner=runner,\n\u001b[32m     17\u001b[39m                                        user_id=USER_ID,\n\u001b[32m     18\u001b[39m                                        session_id=SESSION_ID)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Execute the conversation using await in an async context (like Colab/Jupyter)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_conversation()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# --- OR ---\u001b[39;00m\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Uncomment the following lines if running as a standard Python script (.py file):\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[38;5;66;03m#     except Exception as e:\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m#         print(f\"An error occurred: {e}\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mrun_conversation\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_conversation\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_async(\u001b[33m\"\u001b[39m\u001b[33mWhat is the weather like in London?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m                                        runner=runner,\n\u001b[32m      7\u001b[39m                                        user_id=USER_ID,\n\u001b[32m      8\u001b[39m                                        session_id=SESSION_ID)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_async(\u001b[33m\"\u001b[39m\u001b[33mHow about Paris?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m                                        runner=runner,\n\u001b[32m     12\u001b[39m                                        user_id=USER_ID,\n\u001b[32m     13\u001b[39m                                        session_id=SESSION_ID) \u001b[38;5;66;03m# Expecting the tool's error message\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_async(\u001b[33m\"\u001b[39m\u001b[33mTell me the weather in New York\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m                                        runner=runner,\n\u001b[32m     17\u001b[39m                                        user_id=USER_ID,\n\u001b[32m     18\u001b[39m                                        session_id=SESSION_ID)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mcall_agent_async\u001b[39m\u001b[34m(query, runner, user_id, session_id)\u001b[39m\n\u001b[32m     11\u001b[39m final_response_text = \u001b[33m\"\u001b[39m\u001b[33mAgent did not produce a final response.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Default\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Key Concept: run_async executes the agent logic and yields Events.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# We iterate through events to find the final answer.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# You can uncomment the line below to see *all* events during execution\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\u001b[39;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# Key Concept: is_final_response() marks the concluding message for the turn.\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event.is_final_response():\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m event.content \u001b[38;5;129;01mand\u001b[39;00m event.content.parts:\n\u001b[32m     22\u001b[39m            \u001b[38;5;66;03m# Assuming text response in the first part\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/runners.py:443\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    436\u001b[39m       asyncio.create_task(\n\u001b[32m    437\u001b[39m           _run_compaction_for_sliding_window(\n\u001b[32m    438\u001b[39m               \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    439\u001b[39m           )\n\u001b[32m    440\u001b[39m       )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/runners.py:427\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    421\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    425\u001b[39m     )\n\u001b[32m    426\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/runners.py:653\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    651\u001b[39m   \u001b[38;5;66;03m# Step 2: Otherwise continue with normal execution\u001b[39;00m\n\u001b[32m    652\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    654\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    655\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_append_event(event, is_live_call):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/runners.py:416\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    415\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/agents/base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/agents/llm_agent.py:435\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    433\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:356\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    354\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    357\u001b[39m     last_event = event\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:433\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    422\u001b[39m model_response_event = Event(\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    424\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    425\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    426\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    427\u001b[39m )\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    430\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    431\u001b[39m     )\n\u001b[32m    432\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    434\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    436\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    437\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    441\u001b[39m         )\n\u001b[32m    442\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    443\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:804\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    801\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m804\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:788\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    775\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    776\u001b[39m     llm_request,\n\u001b[32m    777\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    778\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    779\u001b[39m )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    781\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    782\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     )\n\u001b[32m    787\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    789\u001b[39m     trace_call_llm(\n\u001b[32m    790\u001b[39m         invocation_context,\n\u001b[32m    791\u001b[39m         model_response_event.id,\n\u001b[32m    792\u001b[39m         llm_request,\n\u001b[32m    793\u001b[39m         llm_response,\n\u001b[32m    794\u001b[39m     )\n\u001b[32m    795\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:998\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    996\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:982\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    983\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/adk/models/google_llm.py:181\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m close_result\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_client.aio.models.generate_content(\n\u001b[32m    182\u001b[39m       model=llm_request.model,\n\u001b[32m    183\u001b[39m       contents=llm_request.contents,\n\u001b[32m    184\u001b[39m       config=llm_request.config,\n\u001b[32m    185\u001b[39m   )\n\u001b[32m    186\u001b[39m   logger.info(\u001b[33m'\u001b[39m\u001b[33mResponse received from the model.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    187\u001b[39m   logger.debug(_build_response_log(response))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/genai/models.py:6875\u001b[39m, in \u001b[36mAsyncModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   6867\u001b[39m     indices_str = \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, incompatible_tools_indexes))\n\u001b[32m   6868\u001b[39m     logger.warning(\n\u001b[32m   6869\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mTools at indices [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m] are not compatible with automatic function \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   6870\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcalling (AFC). AFC is disabled. If AFC is intended, please \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   6873\u001b[39m         indices_str,\n\u001b[32m   6874\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6875\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content(\n\u001b[32m   6876\u001b[39m       model=model, contents=contents, config=parsed_config\n\u001b[32m   6877\u001b[39m   )\n\u001b[32m   6878\u001b[39m remaining_remote_calls_afc = _extra_utils.get_max_remote_calls_afc(\n\u001b[32m   6879\u001b[39m     parsed_config\n\u001b[32m   6880\u001b[39m )\n\u001b[32m   6881\u001b[39m logger.info(\n\u001b[32m   6882\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAFC is enabled with max remote calls: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremaining_remote_calls_afc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   6883\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/genai/models.py:5693\u001b[39m, in \u001b[36mAsyncModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5690\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   5691\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5693\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.async_request(\n\u001b[32m   5694\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m, path, request_dict, http_options\n\u001b[32m   5695\u001b[39m )\n\u001b[32m   5697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   5698\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5699\u001b[39m ):\n\u001b[32m   5700\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/genai/_api_client.py:1376\u001b[39m, in \u001b[36mBaseApiClient.async_request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masync_request\u001b[39m(\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1367\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1370\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1371\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1372\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1373\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1374\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m   result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_request(\n\u001b[32m   1377\u001b[39m       http_request=http_request, http_options=http_options, stream=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1378\u001b[39m   )\n\u001b[32m   1379\u001b[39m   response_body = result.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1380\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=result.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/genai/_api_client.py:1309\u001b[39m, in \u001b[36mBaseApiClient._async_request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1307\u001b[39m     retry = tenacity.AsyncRetrying(**retry_kwargs)\n\u001b[32m   1308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_retry(  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream\n\u001b[32m   1311\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    151\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/tenacity/_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    116\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/genai/_api_client.py:1254\u001b[39m, in \u001b[36mBaseApiClient._async_request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1246\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aiohttp_session.request(\n\u001b[32m   1247\u001b[39m       method=http_request.method,\n\u001b[32m   1248\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1252\u001b[39m       **\u001b[38;5;28mself\u001b[39m._async_client_session_request_args,\n\u001b[32m   1253\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m errors.APIError.raise_for_async_response(response)\n\u001b[32m   1255\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(response.headers, [\u001b[38;5;28;01mawait\u001b[39;00m response.text()])\n\u001b[32m   1256\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m   1257\u001b[39m     aiohttp.ClientConnectorError,\n\u001b[32m   1258\u001b[39m     aiohttp.ClientConnectorDNSError,\n\u001b[32m   1259\u001b[39m     aiohttp.ClientOSError,\n\u001b[32m   1260\u001b[39m     aiohttp.ServerDisconnectedError,\n\u001b[32m   1261\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/genai/errors.py:188\u001b[39m, in \u001b[36mAPIError.raise_for_async_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    185\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnsupported response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.raise_error_async(status_code, response_json, response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/Sandboxes/agents/.venv/lib/python3.11/site-packages/google/genai/errors.py:210\u001b[39m, in \u001b[36mAPIError.raise_error_async\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    197\u001b[39m \n\u001b[32m    198\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    212\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}"
     ]
    }
   ],
   "source": [
    "# @title Run the Initial Conversation\n",
    "\n",
    "# We need an async function to await our interaction helper\n",
    "async def run_conversation():\n",
    "    await call_agent_async(\"What is the weather like in London?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "    await call_agent_async(\"How about Paris?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID) # Expecting the tool's error message\n",
    "\n",
    "    await call_agent_async(\"Tell me the weather in New York\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "# Execute the conversation using await in an async context (like Colab/Jupyter)\n",
    "await run_conversation()\n",
    "\n",
    "# --- OR ---\n",
    "\n",
    "# Uncomment the following lines if running as a standard Python script (.py file):\n",
    "# import asyncio\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         asyncio.run(run_conversation())\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc75908e",
   "metadata": {},
   "source": [
    "## Test the Agent\n",
    "\n",
    "Run a test query through the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "# response = agent.run(\"Hello, agent!\")\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
